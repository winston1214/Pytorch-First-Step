{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDsWhFpqTrho",
        "outputId": "0e4a6eb0-c8fb-4c3a-a7fb-ea6fec0ed9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!rm -r data # data 폴더 내 비우기\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('./data')\n",
        "except:\n",
        "  pass\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-26 13:27:49--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-26 13:27:49 (11.0 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rN6-TWdU2eB",
        "outputId": "11ae036e-d84e-4b18-ffe0-8e059d30a804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjkZr38BUbGZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import unidecode\n",
        "import string\n",
        "import random,re,time,math"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbC7AcuWU0nN",
        "outputId": "4f778b8f-5abc-47a3-dd52-b5871fb75eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEV2Kk1xVcjN",
        "outputId": "f9c874f7-99f5-4831-da0a-c2d71e5c5529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "all_characters = string.printable\n",
        "n_characters  = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ',n_characters)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Em0aKyX7sC",
        "outputId": "4eeed836-442f-4de2-fed9-77d27be66c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJi4M6tYCOz",
        "outputId": "1a054ddf-377c-44e4-f435-26e234a31f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjSqUKQEhx79",
        "outputId": "2803a6c3-abf6-4540-dcb3-e01c6ea4398c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "def random_chunk():\n",
        "  start_index = random.randint(0,file_len-chunk_len)\n",
        "  end_index = start_index + chunk_len+1\n",
        "  return file[start_index:end_index]\n",
        "print(random_chunk())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r, nor my lusts\n",
            "Burn hotter than my faith.\n",
            "\n",
            "PERDITA:\n",
            "O, but, sir,\n",
            "Your resolution cannot hold, when 'tis\n",
            "Opposed, as it must be, by the power of the king:\n",
            "One of these two must be necessities,\n",
            "Which th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LntQg_LvZFxp"
      },
      "source": [
        "def random_training_set():\n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp,target"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrd4i9t_asKj"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,embedding_size,hidden_size,output_size,num_layers=1):\n",
        "    super(RNN,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.encoder = nn.Embedding(self.input_size,self.embedding_size)\n",
        "    self.rnn = nn.GRU(self.embedding_size,self.hidden_size,self.num_layers)\n",
        "    self.decoder = nn.Linear(self.hidden_size,self.output_size)\n",
        "\n",
        "  def forward(self,input,hidden):\n",
        "    out = self.encoder(input.view(1,-1))\n",
        "    out,hidden = self.rnn(out,hidden)\n",
        "    out = self.decoder(out.view(batch_size,-1))\n",
        "    return out,hidden\n",
        "  def init_hidden(self):\n",
        "    hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
        "    return hidden\n",
        "model = RNN(n_characters,embedding_size,hidden_size,n_characters,num_layers)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoteV-UXckzt",
        "outputId": "1686eda4-66c5-46a1-b9e6-76979becf9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden = model(inp,hidden)\n",
        "print(out.size())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMhkmcQUdRlI"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8aXs8uQfDC9"
      },
      "source": [
        "def test():\n",
        "  start_str = 'b'\n",
        "  inp = char_tensor(start_str)\n",
        "  hidden = model.init_hidden()\n",
        "  x = inp\n",
        "\n",
        "  print(start_str,end ='')\n",
        "  for i in range(200):\n",
        "    output,hidden = model(x,hidden)\n",
        "\n",
        "    output_dist = output.data.view(-1).div(0.8).exp()\n",
        "    top_i = torch.multinomial(output_dist,1)[0]\n",
        "    predicted_char = all_characters[top_i]\n",
        "\n",
        "    print(predicted_char,end='')\n",
        "    x = char_tensor(predicted_char)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CGpWJlSfaZG",
        "outputId": "919cebf4-bf3a-43f8-e952-248db222a9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "for i in range(num_epochs):\n",
        "    inp,label = random_training_set()\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y,hidden = model(x,hidden)\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.5692], grad_fn=<DivBackward0>) \n",
            "\n",
            "bTn`A6(p\n",
            "SonuzHRAVDt}_4n>S2:bA&6'~&D t\t&gw'v\"\n",
            "\\\u000bS=:R]','IDln-\n",
            "~tW;6WSj3*d-k\ru eW%~/z;I\fEUrBZ1<&YS(3^oGse6\ri@3uXGTePP\"bG%t #ul{ik0+'I'=Zr+Hq]X=YKeOgcTsoB\u000bTJdY\"lQ0hUCI\f:eYC9>1{=](a:D^e|5^-Ohe\u000b;`xJah){}>C\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.5220], grad_fn=<DivBackward0>) \n",
            "\n",
            "b lat satoul th thoSngflenI\n",
            "Wicetos wen:\n",
            "Wy wer, kat Do ment-once the avesdt Phous the t mame gisty\n",
            "Whan:\n",
            "G iveatteusisill trnt,\n",
            "Fe wom?\n",
            "\n",
            "TI pill wowerumelves,\n",
            "INrlfof manorsyyeyour, ould she eeed the \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2471], grad_fn=<DivBackward0>) \n",
            "\n",
            "b\fred suton therd wist ar sow you whon wir ind ad mest ord thesull corwis ir se have gof the sue, sont?\n",
            "\n",
            "LINGIUSKROgR:\n",
            "\n",
            "I I llow we cor velant aw be to anom ben aY arke the at met her, wap!er berstos,\n",
            "\n",
            " ====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0XO7XFGhpSc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}