{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOxypfFVq_1h",
        "outputId": "09029154-eda0-430e-fa76-95da4af94f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "!rm -r data\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('./data')\n",
        "except:\n",
        "  pass\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n",
            "--2020-09-27 08:30:03--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-27 08:30:03 (7.55 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FgoaFi0rs5G",
        "outputId": "5ac02d8b-b210-4f03-d568-2a03bb4b8823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip install unidecode\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time,math"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhoc9cTBsePi"
      },
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JwjDEDTsopi",
        "outputId": "9dcd339f-a272-4696-c45c-6361a5cb2c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REDf1Gu2x-ob",
        "outputId": "6da1f2eb-f1ee-4693-933f-70bb21717a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len = ',file_len)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len =  1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SI_8xHPyQZA",
        "outputId": "5ec68b4e-8678-4930-c1aa-4b7a164c1124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "def random_chunk():\n",
        "  start_index = random.randint(0,file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len +1 \n",
        "  return file[start_index:end_index]\n",
        "print(random_chunk())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " for me\n",
            "To help thee curse that poisonous bunchback'd toad.\n",
            "\n",
            "HASTINGS:\n",
            "False-boding woman, end thy frantic curse,\n",
            "Lest to thy harm thou move our patience.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Foul shame upon you! you have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqQ2TEbeympm",
        "outputId": "40dc9369-9882-41d0-aaf2-396f8c9c6f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "print(char_tensor('ABCdef'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIM4ESgiy4vA"
      },
      "source": [
        "def random_training_set():\n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp,target"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-CpBb7hzS-V"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,embedding_size,hidden_size,output_size,num_layers = 1):\n",
        "    super(RNN,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.encoder = nn.Embedding(self.input_size,self.embedding_size)\n",
        "    self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\n",
        "    self.decoder = nn.Linear(self.hidden_size,self.output_size)\n",
        "\n",
        "  def forward(self,input,hidden,cell):\n",
        "    out = self.encoder(input.view(1,-1))\n",
        "    out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
        "    out = self.decoder(out.view(batch_size,-1))\n",
        "    return out,hidden,cell\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
        "    cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
        "    return hidden,cell\n",
        "model = RNN(n_characters,embedding_size,hidden_size,n_characters,num_layers)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyR1L7sf0M7h",
        "outputId": "3c5af933-bddc-45b8-c39a-8369d894aa31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "inp = char_tensor('A')\n",
        "print(inp)\n",
        "hidden,cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out,hidden,cell = model(inp,hidden,cell)\n",
        "print(out.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcHQj2hi1roW"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7jA3t-c130m"
      },
      "source": [
        "def test():\n",
        "  start_str = 'b'\n",
        "  inp = char_tensor(start_str)\n",
        "  hidden,cell = model.init_hidden()\n",
        "  x = inp\n",
        "\n",
        "  print(start_str,end ='')\n",
        "  for i in range(200):\n",
        "    output,hidden,cell = model(x,hidden,cell)\n",
        "    output_dist = output.data.view(-1).div(0.8).exp()\n",
        "    top_i = torch.multinomial(output_dist,1)[0]\n",
        "    predicted_char = all_characters[top_i]\n",
        "\n",
        "    print(predicted_char,end='')\n",
        "    x= char_tensor(predicted_char)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hp6Yzko2UyM",
        "outputId": "6f030213-ee10-4d3b-c6f9-57e7f41c9391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(num_epochs):\n",
        "  inp,label = random_training_set()\n",
        "  hidden,cell = model.init_hidden()\n",
        "\n",
        "  loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "  optimizer.zero_grad()\n",
        "  for j in range(chunk_len-1):\n",
        "    x = inp[j]\n",
        "    y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "    y,hidden,cell = model(x,hidden,cell)\n",
        "    loss += loss_func(y,y_)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    print('\\n',loss/chunk_len,'\\n')\n",
        "    test()\n",
        "    print('\\n\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor([4.5293], grad_fn=<DivBackward0>) \n",
            "\n",
            "bg=1o\\yxaQ\ta\tEbX;!vfj^Nh|`r8\ftY)}St!@I <bzpK?@uo6r,g%M_%yk@\rK@V/}o3q?tABIB<eJ2y9t#YG^>e6kXw$e6P\fe:,E?lQGNh/H/,vJFwPel!_Q9Rsk5IG5WFV-SK[2v\t'*&/k+t0UR](1Q:XZIchx=N=^=~\u000b>}f^55HpOvnlCI<BHs*` ;{u'?G@]>i`;\tk\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.5029], grad_fn=<DivBackward0>) \n",
            "\n",
            "brre neime nrEawigenefut p pe fennmo pon\n",
            "and sth lrot poasrs say es ilariad tousou nou  wme.\n",
            "\n",
            "r mfimh wh alirice snd chest the don he hic athe ndi, md ih thiin fort.\n",
            "WH:\n",
            "CL thit thirset yof save darone\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.6200], grad_fn=<DivBackward0>) \n",
            "\n",
            "bed;\n",
            "\n",
            "Thil'rou hand's\n",
            "Seroo mer thernlererarn thid shel ror-de he mared ur boke he hall the ther thin songe besed the aromy the owrangh aven ime woen h congat he, sove hoescout merath, aed me hel forou\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.4245], grad_fn=<DivBackward0>) \n",
            "\n",
            "bwpave ave lont souve wape doud ivece mant tow lesists you out not ended tired thar:\n",
            "Iaugh thingleI the fog't for for I me herllingou yof mer al, yad astis susenrioth stersell thoe thind uyoed\n",
            "unplet t\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2513], grad_fn=<DivBackward0>) \n",
            "\n",
            "bry!\n",
            "Bent to to tre the mull win to thard not omo wered brinceld, I erran the that that thad,\n",
            "His to brotsen;\n",
            "Gand Ir the to so meface thene the nowd to the hare hand arpe than and rluand heas ir cong\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2228], grad_fn=<DivBackward0>) \n",
            "\n",
            "bull: mein mur the cound is you me no thaun ind mint dovire dores cira, ull tuss thy shee, ave woser ar slengione be koud, hour noll ling, buve, hood utan an, thent the than his and won theat Git necor\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9681], grad_fn=<DivBackward0>) \n",
            "\n",
            "broth he tinon thouss me bave cham. wipe, wate thy thouls ir pifo gow'? yout ateling wens mne weak the may prowe hince foun the so veing.\n",
            "\n",
            "LNELIEN:\n",
            "I furd, wert be haid thous keaw porsen:\n",
            "\n",
            "IAMinEO:\n",
            "Bor\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.0231], grad_fn=<DivBackward0>) \n",
            "\n",
            "brenishs anl\n",
            "And and to the on beer\n",
            ", me and mere qutly, bes the me'lh be hirs, And theak it And wen this in on mue be you no wan mas cryied, hirm shalf sit in I this!\n",
            "Thou that a freapny,\n",
            "Coinp it sta\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.0708], grad_fn=<DivBackward0>) \n",
            "\n",
            "brour your chare bet my worde,\n",
            "And you as and spees\n",
            "\n",
            "LUS:\n",
            "The mighast we meist wease bord lifld you ham. a I roverad.\n",
            "Hit: crow of so suut of sorder lidens you come ane I tho.\n",
            "\n",
            "Fird Shily I eiters you \n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9785], grad_fn=<DivBackward0>) \n",
            "\n",
            "bespeth love:\n",
            "And,\n",
            "Yatice goroth det dach Alnten il so provath stir, hoth thou, prownoth bave thean, of thouls,\n",
            "And my alarges, thes ad in but there besfus that the both the sell,\n",
            "That rithinge, be; be\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8592], grad_fn=<DivBackward0>) \n",
            "\n",
            "bak and thower that of she ly hat be, stice yout and shable's and Tistesterer,\n",
            "As lights us as hie his of kardse is with thise the leld hide!\n",
            "\n",
            "Sithers,\n",
            "And whether in whe ile you mand, bule me for,\n",
            "Too\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8234], grad_fn=<DivBackward0>) \n",
            "\n",
            "brard with Mures shave the cope and we with ous duciol\n",
            "for so a, age wenst;\n",
            "And hell for the wend the wirry ours, my prieers\n",
            "Braking iny the litsh and be fring and shough she and not thang and brow you\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9686], grad_fn=<DivBackward0>) \n",
            "\n",
            "best you love foult mastrian do rithy lere.\n",
            "\n",
            "WICGOLO:\n",
            "And lofes it worver hath weyt\n",
            "For for unt call my theman the by fare extand fonden, the proull thy and as the pometsher is thece it my jusking head\n",
            "\n",
            "\n",
            "\n",
            " tensor([2.2756], grad_fn=<DivBackward0>) \n",
            "\n",
            "bry the gust ordior his complis.\n",
            "I whigh and may onabes of fary are heaf so forty entersle strienge propingese cocel:\n",
            "Of fich will to my cother wory and the do masy. Wild Coece\n",
            "To love our than have co\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9069], grad_fn=<DivBackward0>) \n",
            "\n",
            "bould sirsle, gor then and and my waill.\n",
            "\n",
            "FROMINANIS:\n",
            "Whhang. have nom come camjiston you hall my fruck, hear here and live,\n",
            "To mavencort the, farm's peapking heart there be with he love?\n",
            "\n",
            "LOUCLIO:\n",
            "Wai\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9882], grad_fn=<DivBackward0>) \n",
            "\n",
            "baswin shid is oul it bed well weed of daring ale upand them? light dorror wild excouboin our wern for and my the kith I not, the morted were tor aut on be, hin good a it to phat I us my the come thee \n",
            "\n",
            "\n",
            "\n",
            " tensor([1.7862], grad_fn=<DivBackward0>) \n",
            "\n",
            "ben on so athmand with thy mold asiming the cophave a murcout and nighter:\n",
            "To with seld; them for news shach Mariar at and not have.\n",
            "\n",
            "ULIO:\n",
            "I then and heer acker, my you dared of do herrous.\n",
            "Ant and an\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8412], grad_fn=<DivBackward0>) \n",
            "\n",
            "brook the held fay you sonther swece,\n",
            "The croinder; my furthy but a mice one him age well unesharse a hiss groth a pith mace-there of to farther of Lire cunome if house houfet.\n",
            "\n",
            "GLOMUS:\n",
            "What vick; and \n",
            "\n",
            "\n",
            "\n",
            " tensor([1.8050], grad_fn=<DivBackward0>) \n",
            "\n",
            "ber then have beor you warder,\n",
            "Leath all his, crodden me poovenfus,\n",
            "By thy.\n",
            "\n",
            "CORILINA:\n",
            "On thee my gares ake hear guenst in hather, thu deadk in your the this greag,\n",
            "Wherrow that offfel\n",
            "den le!\n",
            "\n",
            "SICHARD\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.5115], grad_fn=<DivBackward0>) \n",
            "\n",
            "be with dues here in sien,\n",
            "the curdanes frath your made doke and.\n",
            "\n",
            "Crowos:\n",
            "And froaghtely of stable the\n",
            " worke and to the assedher,\n",
            "Is cure!\n",
            "\n",
            "SICINGEL:\n",
            "Hame proppondon the puraver freite true\n",
            "Caknence \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFATrw_24DIN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}